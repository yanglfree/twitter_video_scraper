# twitter_video_scraper
crawl twitter video 

çˆ¬å–twitterä¸ªäººä¸»é¡µè§†é¢‘ã€‚

ç›®å‰ä»…å®ç°æ‰‹åŠ¨è¾“å…¥user_idæ¥çˆ¬å–æŸä¸ªç”¨æˆ·çš„twitteræ—¶é—´çº¿çš„è§†é¢‘æ–‡ä»¶ã€‚

å¯ä»¥çˆ¬å–ä¸ªäººé¦–é¡µä¸Šæ—¶é—´çº¿çš„æ‰€æœ‰ç”¨æˆ·çš„ï¼Œæˆ–è€…followingç”¨æˆ·æˆ–è€…followerç”¨æˆ·çš„idï¼Œç„¶åæ‰¹é‡è·å–æ—¶é—´çº¿è§†é¢‘ï¼Œè¿™é‡Œæ²¡æœ‰å»åšè¿™ä¸ªã€‚

è¿™ä¸ªå¥½å®ç°ï¼Œhttpè¯·æ±‚åœ°å€å’Œè¯·æ±‚å‚æ•°å·²æœ‰ã€‚è¿™é‡Œå°±ä¸å…·ä½“ä»‹ç»äº†ã€‚


ç”¨æµè§ˆå™¨å·¥å…·åˆ†æå¾—åˆ°è·å–timelineçš„apiï¼Œä»¥åŠparamså‚æ•°ï¼Œä¸‹æ‹‰ç¿»é¡µç”¨çš„æ˜¯cursorï¼Œé¦–æ¬¡åŠ è½½cursorä¸ºç©ºï¼Œä»¥åæ¯æ¬¡çš„cursoréƒ½æ˜¯ä»å‰ä¸€æ¬¡çš„apiä¸­è¿”å›çš„ã€‚ å› ä¸ºtwitterä¸èƒ½è®¿é—®ï¼Œæ‰€ä»¥è®°å¾—è¿™é‡Œè¦è®¾ç½®ä»£ç†ã€‚
``` python
def crawl_data(cursor_id):
    if cursor_id == "":
        url = "https://api.twitter.com/2/timeline/profile/{}.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_composer_source=true&include_ext_alt_text=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&include_tweet_replies=false&userId={}&count=20&ext=mediaStats%2ChighlightedLabel%2CcameraMoment".format(user_id,user_id);
    else:
        url = "https://api.twitter.com/2/timeline/profile/{}.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_composer_source=true&include_ext_alt_text=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&include_tweet_replies=false&userId={}&count=20&ext=mediaStats%2ChighlightedLabel%2CcameraMoment&cursor={}".format(user_id,user_id,cursor_id);
    response = requests.get(url, headers=headers, proxies=proxies)
    if response.status_code == 200:
        print("response is: ",response)
        try:
            response_dic = json.loads(response.text)
            # è·å–å›¾ç‰‡åœ°å€ï¼Œå­˜å…¥æ•°æ®åº“
            # handle_pic(response_dic)
            #è·å–è§†é¢‘åœ°å€ï¼Œå­˜å…¥æ•°æ®åº“
            handle_video(response_dic)
            # è·å–cursor ç¿»ä¸‹ä¸€é¡µ
            request_next(response_dic)
        except Exception as e:
            print('error is ', e)

```

è§£æjsonï¼Œè·å¾—è§†é¢‘çš„ä¸‹è½½åœ°å€ã€‚æœ‰å¤šä¸ªç ç‡ï¼Œè·å–ç ç‡æœ€å¤§çš„é‚£ä¸ªï¼Œæ¸…æ™°åº¦æœ€å¥½ã€‚

``` python
def handle_video(dic):
    # è·å–è§†é¢‘ä¸‹è½½åœ°å€ å¹¶å­˜å…¥æ•°æ®åº“
    tweets_dic = dic["globalObjects"]["tweets"]
    if tweets_dic == '':
        return
    tweets = tweets_dic.values()
    video_url_list = []
    for tweet in tweets:
        if "extended_entities" in tweet:
            media = tweet["extended_entities"]["media"][0]
            if "video_info" in media.keys():
                videos = media["video_info"]["variants"]
                max = 0
                video_url = ""
                for video in videos:
                    if video["content_type"] == "video/mp4":
                        # æ’åº é€‰å‡ºç ç‡æœ€å¤§çš„è§†é¢‘
                        if video["bitrate"] > max:
                            max = video["bitrate"]
                            video_url = video["url"].split("?tag")[0]
                video_url_list.append({"video_url": video_url})
                print('url is ',video_url, 'bitrate is', max)
                # download_mp4(video_url)
    # print("video get successed, video_urls is", video_url_list)
    save_mongo(video_url_list)
```

çˆ¬å–ä¸‹æ‹‰åçš„æ–°ä¸€é¡µï¼š
``` python
def request_next(dic):
    instructions = dic["timeline"]["instructions"]
    for instruction in instructions:
        if "addEntries" in instruction.keys():
            entries = instruction["addEntries"]["entries"]
            for entry in entries:
                content = entry["content"]
                if "operation" in content.keys():
                    #å¸¦æœ‰cursorçš„å­—å…¸
                    cursor = content["operation"]["cursor"]
                    if "stopOnEmptyResponse" in cursor.keys():
                        #æœ€ç»ˆçš„cursor
                        cursor_id = cursor["value"]
                        print("cursor_id is ",cursor_id)
                        break
    # è·å¾—cursor_idåçˆ¬å–ä¸‹ä¸€é¡µ
    time.sleep(5)
    if cursor_id != "":
        crawl_data(cursor_id)
```

æœ€åä»mongoè¯»å–å‡ºä¸‹è½½åœ°å€ï¼Œç”¨å¤šçº¿ç¨‹ä¸‹è½½ã€‚
``` python
if __name__ == "__main__":
    temps = collection.find({"video_url": {'$regex': '^http.*'}})
    videos = list(temps)
    for i in (1,10):
        t = threading.Thread(target=download_video, args=(videos,))
        t.start()
```

å¼€å§‹ä¸‹è½½
``` python
def download_video(videos):
    while videos:
        lock.acquire()
        video = videos[0]
        del videos[0]
        lock.release()
        download(video["video_url"])

def download(url):
    print("url is", url)
    try:
        response = requests.get(url, proxies=proxies)
        with open((path + "/video/{}.mp4").format(get_md5(url)), "wb") as f:
            f.write(response.content)
    except Exception as e:
        print(e)
```
çˆ¬äº†å‡ ä¸ªç”¨æˆ·çš„é¡µé¢ï¼Œä¸‹äº†å‡ ç™¾ä¸ªè§†é¢‘ï¼Œè¿˜æœ‰ä¸€äº›ä¸‹è½½å¤±è´¥äº†ï¼Œ503ã€‚è¢«å±è”½äº†å§ã€‚

![](http://ww1.sinaimg.cn/large/007dl3HPly1g5o0c9opw4j304i05ot93.jpg)
æœ‰äº›å°è§†é¢‘åœ¨å¼€è½¦ï¼Œè¿™é‡Œå°±ä¸ä¸Šå›¾äº†ã€‚ğŸ˜€
